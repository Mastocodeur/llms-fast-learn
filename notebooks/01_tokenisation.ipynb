{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e03276",
   "metadata": {},
   "source": [
    "# Comprendre et manipuler la tokenisation dans les LLM\n",
    "\n",
    "Ce notebook a pour objectif d‚Äôintroduire la tokenisation, une √©tape fondamentale\n",
    "dans le fonctionnement des mod√®les de langage de grande taille (LLM).\n",
    "\n",
    "La tokenisation constitue l‚Äôinterface entre le langage naturel et les mod√®les\n",
    "num√©riques : elle d√©termine comment un texte est d√©coup√©, repr√©sent√© et interpr√©t√©\n",
    "par un mod√®le.\n",
    "\n",
    "√Ä la fin de ce notebook, vous serez capable de :\n",
    "- expliquer ce qu‚Äôest un token et un tokenizer,\n",
    "- comparer diff√©rentes strat√©gies de tokenisation,\n",
    "- manipuler des tokenizers modernes utilis√©s dans les LLM,\n",
    "- comprendre l‚Äôimpact de la tokenisation sur les performances et les co√ªts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bcba1",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b79ae0",
   "metadata": {},
   "source": [
    "# Pourquoi la tokenisation est n√©cessaire\n",
    "## 1. Du texte au num√©rique\n",
    "\n",
    "Un mod√®le de langage est un mod√®le math√©matique : il ne peut pas traiter directement\n",
    "du texte brut. Toute information doit √™tre repr√©sent√©e sous forme num√©rique.\n",
    "\n",
    "La tokenisation est le processus qui permet de transformer un texte en une s√©quence\n",
    "d‚Äôunit√©s discr√®tes appel√©es *tokens*, lesquelles seront ensuite converties en\n",
    "repr√©sentations num√©riques exploitables par le mod√®le.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1aaf82",
   "metadata": {},
   "source": [
    "## 2. Qu‚Äôest-ce qu‚Äôun token ?\n",
    "\n",
    "Un token est l‚Äôunit√© de base manipul√©e par un mod√®le de langage.\n",
    "Il ne correspond pas n√©cessairement √† un mot entier : il peut s‚Äôagir d‚Äôune partie de\n",
    "mot, d‚Äôun caract√®re, d‚Äôun nombre ou d‚Äôun symbole.\n",
    "\n",
    "Le d√©coupage en tokens d√©pend enti√®rement du *tokenizer* utilis√©.\n",
    "Un m√™me texte peut donc √™tre d√©coup√© diff√©remment selon le mod√®le.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad31d87",
   "metadata": {},
   "source": [
    "## 3. Qu‚Äôest-ce qu‚Äôun tokenizer ?\n",
    "\n",
    "Un tokenizer est le composant charg√© de transformer un texte brut en une s√©quence de tokens selon un ensemble de r√®gles et de param√®tres appris ou d√©finis. \n",
    "\n",
    "Il d√©termine la mani√®re dont le texte est d√©coup√©, quels symboles sont reconnus comme des unit√©s valides et comment ces unit√©s sont associ√©es √† des identifiants num√©riques. \n",
    "\n",
    "Le tokenizer joue un r√¥le central dans le fonctionnement d‚Äôun mod√®le de langage, car il conditionne la repr√©sentation du texte, la taille du vocabulaire, la longueur des s√©quences et, par cons√©quent, les performances et le co√ªt computationnel du mod√®le. \n",
    "\n",
    "Chaque tokenizer est sp√©cifiquement con√ßu pour √™tre compatible avec un mod√®le donn√©, et toute incoh√©rence entre le tokenizer et le mod√®le entra√Æne une d√©gradation significative des r√©sultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f59420",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986b62e9",
   "metadata": {},
   "source": [
    "# Les diff√©rentes tokenisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4a5e6",
   "metadata": {},
   "source": [
    "## Tokenisation na√Øve par mots\n",
    "\n",
    "Le texte est d√©coup√© en mots entiers s√©par√©s par des espaces ou des signes de ponctuation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19526f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Les', 'mod√®les', 'de', 'langage', 'sont', 'fascinants.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Les mod√®les de langage sont fascinants.\"\n",
    "tokens = text.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8200ff4",
   "metadata": {},
   "source": [
    "Cette approche est simple mais pose rapidement probl√®me :\n",
    "- le vocabulaire devient tr√®s grand,\n",
    "- les mots inconnus ne peuvent pas √™tre repr√©sent√©s,\n",
    "- la g√©n√©ralisation est limit√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a045d",
   "metadata": {},
   "source": [
    "## Tokenisation par caract√®res\n",
    "\n",
    "Chaque caract√®re du texte est trait√© comme un token, garantissant une couverture compl√®te du vocabulaire au prix de s√©quences tr√®s longues : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e313de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " '√®',\n",
       " 'l',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'a',\n",
       " 'n',\n",
       " 'g',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 's',\n",
       " 'c',\n",
       " 'i',\n",
       " 'n',\n",
       " 'a',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50b92e",
   "metadata": {},
   "source": [
    "La tokenisation par caract√®res r√©sout le probl√®me des mots inconnus,\n",
    "mais elle produit des s√©quences tr√®s longues, ce qui augmente fortement\n",
    "le co√ªt computationnel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aefa78",
   "metadata": {},
   "source": [
    "## Tokenisation par sous-mots\n",
    "\n",
    "Les LLM modernes utilisent majoritairement des tokenizations bas√©es sur des sous-mots.\n",
    "L‚Äôid√©e est de d√©couper les mots en unit√©s fr√©quentes, r√©utilisables, permettant\n",
    "de g√©rer efficacement les mots rares ou inconnus.\n",
    "\n",
    "Exemple :\n",
    "- \"incompr√©hensible\" ‚Üí \"in\" + \"compr√©hens\" + \"ible\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f1a3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435ab018b5df4fde934244734c6ef24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103dfa3e19394834994634ded8f52aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82907c6d09514ed2a2cbfa76e1809f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba46805d58546d2809215766be2388b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['token',\n",
       " '##ization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'step',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Tokenization is a crucial step in natural language processing.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25354840",
   "metadata": {},
   "source": [
    "On observe que le texte est d√©coup√© en sous-unit√©s, et non en mots stricts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e68fd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 19204, 3989, 2003, 1037, 10232, 3357, 1999, 3019, 2653, 6364, 1012, 102]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.encode(text)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064e636",
   "metadata": {},
   "source": [
    "Les mod√®les ne manipulent pas directement les tokens textuels, mais leurs identifiants num√©riques associ√©s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35d0bb7",
   "metadata": {},
   "source": [
    "## Tokenisation au niveau des bytes (byte-level tokenization)  \n",
    "\n",
    "Le texte est tokenis√© √† partir des octets qui le composent, assurant une repr√©sentation universelle et ind√©pendante de la langue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae754e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Prix : 199,99\\xe2\\x82\\xac \\xf0\\x9f\\x98\\x84'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Prix : 199,99‚Ç¨ üòÑ\"\n",
    "\n",
    "# Encodage UTF-8 en bytes\n",
    "byte_tokens = text.encode(\"utf-8\")\n",
    "\n",
    "byte_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec46ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[80,\n",
       " 114,\n",
       " 105,\n",
       " 120,\n",
       " 32,\n",
       " 58,\n",
       " 32,\n",
       " 49,\n",
       " 57,\n",
       " 57,\n",
       " 44,\n",
       " 57,\n",
       " 57,\n",
       " 226,\n",
       " 130,\n",
       " 172,\n",
       " 32,\n",
       " 240,\n",
       " 159,\n",
       " 152,\n",
       " 132]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(byte_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c9e2595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prix : 199,99‚Ç¨ üòÑ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes(byte_tokens).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b532a7a",
   "metadata": {},
   "source": [
    "## Tokenisation hybride \n",
    "\n",
    "Plusieurs niveaux de tokenisation sont combin√©s afin d‚Äô√©quilibrer robustesse, efficacit√© et pr√©cision selon le contexte d‚Äôutilisation.\n",
    "\n",
    "Principe :\n",
    "* on tokenise d‚Äôabord par mots connus,\n",
    "* sinon on d√©coupe en sous-mots,\n",
    "* sinon on retombe au niveau byte ou caract√®re."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d7180a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chat',\n",
       " 'G',\n",
       " 'PT',\n",
       " 'ification',\n",
       " 'ƒ†ultra',\n",
       " '-',\n",
       " 'm',\n",
       " '√É¬©',\n",
       " 'ta',\n",
       " '-',\n",
       " 'quant',\n",
       " 'ique',\n",
       " 'ƒ†√∞≈Åƒ∫',\n",
       " 'ƒ¶']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "text = \"ChatGPTification ultra-m√©ta-quantique üòÑ\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b387d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30820,\n",
       " 38,\n",
       " 11571,\n",
       " 2649,\n",
       " 14764,\n",
       " 12,\n",
       " 76,\n",
       " 2634,\n",
       " 8326,\n",
       " 12,\n",
       " 40972,\n",
       " 2350,\n",
       " 30325,\n",
       " 226]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa4ecf9",
   "metadata": {},
   "source": [
    "## Reconstruction du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72e79630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'token',\n",
       " '##ization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'step',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915e7f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] tokenization is a crucial step in natural language processing. [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433da02b",
   "metadata": {},
   "source": [
    "## Comparaison de tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86b630c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer: bert-base-uncased\n",
      "['l', \"'\", 'international', '##isation', 'des', 'model', '##es', 'de', 'lang', '##age', 'est', 'complex', '##e', '.']\n",
      "Nombre de tokens: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5960ec5e6144f9806027c242c54c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4134d86a734e3c8a35b91c0c9f0e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d668566ca704f52971fe90cb55e989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1422424e7cff4127990032952324dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b0586df3c54f789970a455885e7ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer: gpt2\n",
      "['L', \"'\", 'international', 'isation', 'ƒ†des', 'ƒ†mod', '√É¬®', 'les', 'ƒ†de', 'ƒ†lang', 'age', 'ƒ†est', 'ƒ†complex', 'e', '.']\n",
      "Nombre de tokens: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909e9feb726940dc9d55276baa467082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d132a22349c048bc9cceaf5551a8c080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ee348ab69e47b4a157ffae8df58d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83256eda8d844d0d8fd0321c43cb0799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer: xlm-roberta-base\n",
      "['‚ñÅL', \"'\", 'international', 'isation', '‚ñÅdes', '‚ñÅmod√®les', '‚ñÅde', '‚ñÅlang', 'age', '‚ñÅest', '‚ñÅcomplexe', '.']\n",
      "Nombre de tokens: 12\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"gpt2\",\n",
    "    \"xlm-roberta-base\"\n",
    "]\n",
    "\n",
    "text = \"L'internationalisation des mod√®les de langage est complexe.\"\n",
    "\n",
    "for model in models:\n",
    "    tok = AutoTokenizer.from_pretrained(model)\n",
    "    print(f\"\\nTokenizer: {model}\")\n",
    "    print(tok.tokenize(text))\n",
    "    print(\"Nombre de tokens:\", len(tok.tokenize(text)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec28cb",
   "metadata": {},
   "source": [
    "## Impact pratique de la tokenisation\n",
    "\n",
    "Les limites de contexte des LLM sont exprim√©es en nombre de tokens,\n",
    "pas en nombre de mots ou de caract√®res.\n",
    "\n",
    "Deux textes de longueur similaire peuvent donc avoir des co√ªts tr√®s diff√©rents\n",
    "selon leur tokenisation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9a99f",
   "metadata": {},
   "source": [
    "## Cas limites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cfd41da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTification ultra-m√©ta-quantique\n",
      "['chat', '##gp', '##ti', '##fication', 'ultra', '-', 'meta', '-', 'quan', '##tique']\n",
      "\n",
      "Prix : 199,99‚Ç¨ üòÑ\n",
      "['prix', ':', '199', ',', '99', '##‚Ç¨', '[UNK]']\n",
      "\n",
      "anticonstitutionnellement\n",
      "['anti', '##con', '##sti', '##tu', '##tion', '##nell', '##ement']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"ChatGPTification ultra-m√©ta-quantique\",\n",
    "    \"Prix : 199,99‚Ç¨ üòÑ\",\n",
    "    \"anticonstitutionnellement\"\n",
    "]\n",
    "\n",
    "for t in texts:\n",
    "    print(t)\n",
    "    print(tokenizer.tokenize(t))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66ed14",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "La tokenisation est une √©tape fondamentale dans les LLM.\n",
    "Elle conditionne la repr√©sentation du texte, la longueur des s√©quences,\n",
    "les performances des mod√®les et leur co√ªt d‚Äôutilisation.\n",
    "\n",
    "Comprendre la tokenisation, c‚Äôest comprendre comment un mod√®le de langage\n",
    "lit r√©ellement le langage humain.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
